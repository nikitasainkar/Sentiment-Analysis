{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe73c099",
   "metadata": {},
   "source": [
    "# Amazon Baby Products Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac90387",
   "metadata": {},
   "source": [
    "Sentiment analysis is one of the most important parts of Natural Language Processing. It is different than machine learning with numeric data because text data cannot be processed by an algorithm directly. It needs to be transformed into a numeric form. So, text data are vectorized before they get fed into the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870498b",
   "metadata": {},
   "source": [
    "## About the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096da4ff",
   "metadata": {},
   "source": [
    "The original dataset has three features: name(name of the products), review(Customer reviews of the products), and rating(rating of the customer of a product ranging from 1 to 5). The review column will be the input column and the rating column will be used to understand the sentiments of the review. Here are some important data preprocessing steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dda375",
   "metadata": {},
   "source": [
    "- The dataset has about 183,500 rows of data. There are 1147 null values. I simply will get rid of those null values.\n",
    "\n",
    "- As the dataset is pretty big, it takes a lot of time to run some machine learning algorithm. So, I used 30% of the data for this project which is still 54,000 data. The sample was representative.\n",
    "\n",
    "- If the rating is 1 and 2 that will be considered a bad review or negative review. And if the review is 3, 4, and 5, the review will be considered as a good review or positive review. So, I added a new column named ‘sentiments’ to the dataset that will use 1 for the positive reviews and 0 for the negative reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5ae0c",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b43393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8b8e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183531 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \n",
       "0       These flannel wipes are OK, but in my opinion ...       3  \n",
       "1       it came early and was not disappointed. i love...       5  \n",
       "2       Very soft and comfortable and warmer than it l...       5  \n",
       "3       This is a product well worth the purchase.  I ...       5  \n",
       "4       All of my kids have cried non-stop when I trie...       5  \n",
       "...                                                   ...     ...  \n",
       "183526  Such a great idea! very handy to have and look...       5  \n",
       "183527  This product rocks!  It is a great blend of fu...       5  \n",
       "183528  This item looks great and cool for my kids.......       5  \n",
       "183529  I am extremely happy with this product. I have...       5  \n",
       "183530  I love this product very mush . I have bought ...       5  \n",
       "\n",
       "[183531 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('amazon_baby.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949108e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183531, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e06d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   name    183213 non-null  object\n",
      " 1   review  182702 non-null  object\n",
      " 2   rating  183531 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84813fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>183531.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.120448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.285017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rating\n",
       "count  183531.000000\n",
       "mean        4.120448\n",
       "std         1.285017\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         5.000000\n",
       "max         5.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b169a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149dc3b2",
   "metadata": {},
   "source": [
    "## Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fdddec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         These flannel wipes are OK, but in my opinion ...\n",
       "1         it came early and was not disappointed. i love...\n",
       "2         Very soft and comfortable and warmer than it l...\n",
       "3         This is a product well worth the purchase.  I ...\n",
       "4         All of my kids have cried non-stop when I trie...\n",
       "                                ...                        \n",
       "183526    Such a great idea! very handy to have and look...\n",
       "183527    This product rocks!  It is a great blend of fu...\n",
       "183528    This item looks great and cool for my kids.......\n",
       "183529    I am extremely happy with this product. I have...\n",
       "183530    I love this product very mush . I have bought ...\n",
       "Name: review, Length: 182384, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e0c29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\AppData\\Local\\Temp/ipykernel_27972/3444821513.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['review_processed'] = df['review'].str.replace(\"[^a-zA-Z0-9]\", \" \")\n",
      "C:\\Users\\Nikita\\AppData\\Local\\Temp/ipykernel_27972/3444821513.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review_processed'] = df['review'].str.replace(\"[^a-zA-Z0-9]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "df['review_processed'] = df['review'].str.replace(\"[^a-zA-Z0-9]\", \" \")\n",
    "\n",
    "# Re ordering columns\n",
    "df = df[['review','review_processed','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3638a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         These flannel wipes are OK  but in my opinion ...\n",
       "1         it came early and was not disappointed  i love...\n",
       "2         Very soft and comfortable and warmer than it l...\n",
       "3         This is a product well worth the purchase   I ...\n",
       "4         All of my kids have cried non stop when I trie...\n",
       "                                ...                        \n",
       "183526    Such a great idea  very handy to have and look...\n",
       "183527    This product rocks   It is a great blend of fu...\n",
       "183528    This item looks great and cool for my kids    ...\n",
       "183529    I am extremely happy with this product  I have...\n",
       "183530    I love this product very mush   I have bought ...\n",
       "Name: review_processed, Length: 182384, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3bad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "df1 = df.sample(frac = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edeb03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sentiments'] = df1.rating.apply(lambda x: 0 if x in [1, 2] else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00df02ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_processed</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165191</th>\n",
       "      <td>An off-white or cream sheet that is so soft. I...</td>\n",
       "      <td>An off white or cream sheet that is so soft  I...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108775</th>\n",
       "      <td>I was skeptical about how well these will work...</td>\n",
       "      <td>I was skeptical about how well these will work...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162820</th>\n",
       "      <td>It soft and material appears to be excellent. ...</td>\n",
       "      <td>It soft and material appears to be excellent  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148217</th>\n",
       "      <td>This is a very nice cover. I have two because ...</td>\n",
       "      <td>This is a very nice cover  I have two because ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46428</th>\n",
       "      <td>I love these Lovies. They are cute, soft and d...</td>\n",
       "      <td>I love these Lovies  They are cute  soft and d...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137608</th>\n",
       "      <td>Fit my Jenny Lind crib perfectly. Water proof ...</td>\n",
       "      <td>Fit my Jenny Lind crib perfectly  Water proof ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156932</th>\n",
       "      <td>I purchased this and returned it immediately b...</td>\n",
       "      <td>I purchased this and returned it immediately b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171309</th>\n",
       "      <td>I love this diaper bag. Everywhere I go with m...</td>\n",
       "      <td>I love this diaper bag  Everywhere I go with m...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57598</th>\n",
       "      <td>This is Pancake Bear number 4 for our house.  ...</td>\n",
       "      <td>This is Pancake Bear number 4 for our house   ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>The Snuzzler is perfect for my baby boy. It ma...</td>\n",
       "      <td>The Snuzzler is perfect for my baby boy  It ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54715 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  \\\n",
       "165191  An off-white or cream sheet that is so soft. I...   \n",
       "108775  I was skeptical about how well these will work...   \n",
       "162820  It soft and material appears to be excellent. ...   \n",
       "148217  This is a very nice cover. I have two because ...   \n",
       "46428   I love these Lovies. They are cute, soft and d...   \n",
       "...                                                   ...   \n",
       "137608  Fit my Jenny Lind crib perfectly. Water proof ...   \n",
       "156932  I purchased this and returned it immediately b...   \n",
       "171309  I love this diaper bag. Everywhere I go with m...   \n",
       "57598   This is Pancake Bear number 4 for our house.  ...   \n",
       "99994   The Snuzzler is perfect for my baby boy. It ma...   \n",
       "\n",
       "                                         review_processed  rating  sentiments  \n",
       "165191  An off white or cream sheet that is so soft  I...       5           1  \n",
       "108775  I was skeptical about how well these will work...       5           1  \n",
       "162820  It soft and material appears to be excellent  ...       5           1  \n",
       "148217  This is a very nice cover  I have two because ...       5           1  \n",
       "46428   I love these Lovies  They are cute  soft and d...       5           1  \n",
       "...                                                   ...     ...         ...  \n",
       "137608  Fit my Jenny Lind crib perfectly  Water proof ...       5           1  \n",
       "156932  I purchased this and returned it immediately b...       1           0  \n",
       "171309  I love this diaper bag  Everywhere I go with m...       5           1  \n",
       "57598   This is Pancake Bear number 4 for our house   ...       5           1  \n",
       "99994   The Snuzzler is perfect for my baby boy  It ma...       5           1  \n",
       "\n",
       "[54715 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d21b2f",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70b7c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1['review']\n",
    "y = df1['sentiments']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dae50c",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f81da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd59d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165191    An off-white or cream sheet that is so soft. I...\n",
       "108775    I was skeptical about how well these will work...\n",
       "162820    It soft and material appears to be excellent. ...\n",
       "148217    This is a very nice cover. I have two because ...\n",
       "46428     I love these Lovies. They are cute, soft and d...\n",
       "                                ...                        \n",
       "137608    Fit my Jenny Lind crib perfectly. Water proof ...\n",
       "156932    I purchased this and returned it immediately b...\n",
       "171309    I love this diaper bag. Everywhere I go with m...\n",
       "57598     This is Pancake Bear number 4 for our house.  ...\n",
       "99994     The Snuzzler is perfect for my baby boy. It ma...\n",
       "Name: review, Length: 54715, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb5c91b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165191    1\n",
       "108775    1\n",
       "162820    1\n",
       "148217    1\n",
       "46428     1\n",
       "         ..\n",
       "137608    1\n",
       "156932    0\n",
       "171309    1\n",
       "57598     1\n",
       "99994     1\n",
       "Name: sentiments, Length: 54715, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e3fe41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54715,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdc730d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54715,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7552dd5",
   "metadata": {},
   "source": [
    "## Vectorizing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86321485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0591522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctmTr = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b676ae",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37801aaa",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e56168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#Training the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(ctmTr, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774f12b",
   "metadata": {},
   "source": [
    "### Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d96d80dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression with CountVectorizer\n",
      "0.9045965457370008\n"
     ]
    }
   ],
   "source": [
    "lr_score = lr.score(X_test_dtm, y_test)\n",
    "print(\"Results for Logistic Regression with CountVectorizer\")\n",
    "print(lr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030547ab",
   "metadata": {},
   "source": [
    "### Predicting the labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c859046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lr = lr.predict(X_test_dtm)\n",
    "y_pred_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa07ec2",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "572fd9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa0ddf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934 668 376 8965\n"
     ]
    }
   ],
   "source": [
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811f2b8",
   "metadata": {},
   "source": [
    "### True positive and true negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eee9ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9597 0.583\n"
     ]
    }
   ],
   "source": [
    "tpr_lr = round(tp/(tp + fn), 4)\n",
    "tnr_lr = round(tn/(tn+fp), 4)\n",
    "print(tpr_lr, tnr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c87229",
   "metadata": {},
   "source": [
    "### 2. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b02d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67a32c",
   "metadata": {},
   "source": [
    "### Vectorizing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71358ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "ctmTr = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc51fc",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ab1fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Support Vector Machine with CountVectorizer\n",
      "0.9039568674038198\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svcl = svm.SVC()\n",
    "svcl.fit(ctmTr, y_train)\n",
    "svcl_score = svcl.score(X_test_dtm, y_test)\n",
    "print(\"Results for Support Vector Machine with CountVectorizer\")\n",
    "print(svcl_score)\n",
    "y_pred_sv = svcl.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6ce53",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1d81f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566 948 103 9326\n"
     ]
    }
   ],
   "source": [
    "cm_sv = confusion_matrix(y_test, y_pred_sv)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_sv).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14abeaf9",
   "metadata": {},
   "source": [
    "### True positive and true negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "300695c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9891 0.3738\n"
     ]
    }
   ],
   "source": [
    "tpr_sv = round(tp/(tp + fn), 4)\n",
    "tnr_sv = round(tn/(tn+fp), 4)\n",
    "print(tpr_sv, tnr_sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2c888",
   "metadata": {},
   "source": [
    "### 3. K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3875f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=148)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016bc7b5",
   "metadata": {},
   "source": [
    "### Vectorizing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be59fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "ctmTr = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716b8fd",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNN Classifier with CountVectorizer\n",
      "0.8536050443205703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(ctmTr, y_train)\n",
    "knn_score = knn.score(X_test_dtm, y_test)\n",
    "print(\"Results for KNN Classifier with CountVectorizer\")\n",
    "print(knn_score)\n",
    "y_pred_knn = knn.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b354f9",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b993a3",
   "metadata": {},
   "source": [
    "### True positive and true negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_knn = round(tp/(tp + fn), 4)\n",
    "tnr_knn = round(tn/(tn+fp), 4)\n",
    "print(tpr_knn, tnr_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5c9ee",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff4656",
   "metadata": {},
   "source": [
    "###### Logistic regression was the best out of all three classifiers used for this project considering overall accuracy, true positive rate, and true negative rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb225ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
